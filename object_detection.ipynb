{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtictc4o39ds9LzOnYOyb6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/regiiis/dlv_group_project/blob/main/object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DLV Group Project - **Object Detection**"
      ],
      "metadata": {
        "id": "EPVuJ39E_F6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "Gt8xFiBH_Eg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDHWPqxZ-pmQ",
        "outputId": "efbf2e45-328c-4f4e-88af-5c72cf45ccf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, datetime\n",
        "\n",
        "# General imports\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "\n",
        "# Shortcuts to keras if (however from tensorflow)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard \n",
        "from tensorflow.keras import layers\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import sys\n",
        "\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5-est-O-zN-",
        "outputId": "46a3e418-7ce0-4010-8490-5bef66f13f50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTJF-_R--06v",
        "outputId": "252df28a-2113-4fec-d258-64ab0861b1a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/data/2020-02-14_InfraredSolarModules.zip\""
      ],
      "metadata": {
        "id": "BIxzOskO-22V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(\"/content/InfraredSolarModules/module_metadata.json\",orient=\"index\")\n",
        "df['image_name'] = df['image_filepath'].str[7:]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lRKTvR36-4nX",
        "outputId": "eca68e0a-e957-462a-a092-98fbc7e7c39d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         image_filepath anomaly_class image_name\n",
              "13357  images/13357.jpg    No-Anomaly  13357.jpg\n",
              "13356  images/13356.jpg    No-Anomaly  13356.jpg\n",
              "19719  images/19719.jpg    No-Anomaly  19719.jpg\n",
              "11542  images/11542.jpg    No-Anomaly  11542.jpg\n",
              "11543  images/11543.jpg    No-Anomaly  11543.jpg\n",
              "...                 ...           ...        ...\n",
              "8488    images/8488.jpg    Vegetation   8488.jpg\n",
              "8489    images/8489.jpg    Vegetation   8489.jpg\n",
              "7464    images/7464.jpg      Cracking   7464.jpg\n",
              "18065  images/18065.jpg    No-Anomaly  18065.jpg\n",
              "13354  images/13354.jpg    No-Anomaly  13354.jpg\n",
              "\n",
              "[20000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-326d1136-562c-46cf-8146-33e356c6581d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_filepath</th>\n",
              "      <th>anomaly_class</th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13357</th>\n",
              "      <td>images/13357.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>13357.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13356</th>\n",
              "      <td>images/13356.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>13356.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19719</th>\n",
              "      <td>images/19719.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>19719.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11542</th>\n",
              "      <td>images/11542.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>11542.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11543</th>\n",
              "      <td>images/11543.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>11543.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8488</th>\n",
              "      <td>images/8488.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>8488.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8489</th>\n",
              "      <td>images/8489.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>8489.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7464</th>\n",
              "      <td>images/7464.jpg</td>\n",
              "      <td>Cracking</td>\n",
              "      <td>7464.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18065</th>\n",
              "      <td>images/18065.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>18065.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13354</th>\n",
              "      <td>images/13354.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>13354.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-326d1136-562c-46cf-8146-33e356c6581d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-326d1136-562c-46cf-8146-33e356c6581d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-326d1136-562c-46cf-8146-33e356c6581d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_df = df.sample(frac=0.8,random_state=200)       # random state is a seed value\n",
        "train_df = reduced_df.sample(frac=0.8,random_state=200) # random state is a seed value\n",
        "validation_test_df = reduced_df.drop(train_df.index)\n",
        "validation_df = validation_test_df.sample(frac=0.5,random_state=200)\n",
        "test_df = validation_test_df.drop(validation_df.index)\n",
        "\n",
        "print(train_df.info())\n",
        "print()\n",
        "print(validation_df.info())\n",
        "print()\n",
        "test_df.info()\n",
        "\n",
        "test_df.anomaly_class"
      ],
      "metadata": {
        "id": "VFvRy6Uf-6Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_binarizer(image, treshold, print, save):\n",
        "  dir_path = '/content/binary_images/'\n",
        "  path = \"/content/InfraredSolarModules/images/\" + str(image) + \".jpg\"\n",
        "  imagee = mpimg.imread(path)\n",
        "  img = np.array(imagee)\n",
        "\n",
        "  t = float(treshold)\n",
        "  arr = img\n",
        "  max_num, min_num, i , n = 0, 0, 0, 0\n",
        "\n",
        "  flat_list = [x for xs in arr for x in xs]    # Normalising the image\n",
        "  max_num = max(flat_list)\n",
        "  min_num = min(flat_list)\n",
        "  normdividend = max_num - min_num\n",
        "  a2 = np.array([[(k - min_num) / normdividend for k in j] for j in img])\n",
        "\n",
        "  for list in a2:\n",
        "    for number in list:\n",
        "      if (float(number) < t):\n",
        "        arr[i][n] = 0\n",
        "      else:\n",
        "        arr[i][n] = 1\n",
        "      n = n + 1\n",
        "    i = i + 1\n",
        "    n = 0\n",
        "\n",
        "  if (save == 1):\n",
        "    isExist = os.path.exists(dir_path)\n",
        "    if not isExist:\n",
        "      os.makedirs(dir_path)\n",
        "    data = asarray(arr)\n",
        "    savetxt(dir_path + str(image) + '.csv', data, delimiter=',')\n",
        "\n",
        "  if (print == 1):\n",
        "    fig = plt.figure()\n",
        "    rows, columns = 1 , 2\n",
        "    fig.add_subplot(rows, columns, 1)\n",
        "    plt.imshow(imagee)\n",
        "    fig.add_subplot(rows, columns, 2)\n",
        "    plt.imshow(arr)"
      ],
      "metadata": {
        "id": "ZPkRHjHC-psl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Binary Image Data set"
      ],
      "metadata": {
        "id": "9dsTE0ze_Obw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 20000):\n",
        "  image_binarizer(i, 0.92, 0, 1)"
      ],
      "metadata": {
        "id": "dt9lIxlN-pu5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "1TQMhtws-b_x",
        "outputId": "220856fc-1776-4599-d182-3001541dc488"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAD6CAYAAAAP+OQSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbLUlEQVR4nO3dbYzc13Xf8d+Zp13ukhRFWlFZSq0MQ0lgJI0EbNUUyYvUjlvVCCAFCIIoQKAABpgCNWCjRhE1fdEEaAG/SGygaOGCgVSxgGvHiB3YCJw4iiLAcVHIoh1G0UNsy7YSiabE2BIfdpe783T6YofN7txzuf/Zmbk7O/x+gAV37/7nP3dm7p75c84995q7CwAwXbX97gAA3AoItgBQAMEWAAog2AJAAQRbACiAYAsABYwVbM3sQTP7hpm9YmaPTapTwH5jbGPSbK/zbM2sLumbkt4n6XVJz0l6xN1fyt2mubDsC8vHd7T16/GxHrR77q3BKnT4ZjK396g9d1825nzl6Ly5U/aDgzPHht3KHdsP2nrxsfVOepLo9lL6um2sv61Oe23cV21q9jK2W7bgi1ou1EPMqg2tqe2b4dhujHHeByS94u7fkSQz+7SkhyRlB+TC8nH9k5/90M7OHYsjaPu2tL/dpfi8vVb0h1/9b7nfjKNPvxm0LcQRxRsVg23uDaMW3L4bP4b69fQkljt2I22vteMu1IP21pX4cR250E3aGutxZO4u7Xzn/Is//69xB2bHyGN7Ucv6Z/beQt3DrHrWn87+bpyPEU5Jem3bz68P2oCDjrGNiRvnyrYSMzst6bQktZaOTfvugGK2j+1FZf7bBQyMc2V7QdLd236+a9C2g7ufcfcVd19pLhwe4+6AYkYf21oo1jkcTONc2T4n6V4ze6e2BuIvSfrlm92g15Ku3b3z87vNzMVu+0Tw+d/RTnhsazFtbzTiz1ZbjfSzxkOt+LzNWnqOpWb8gefxhfWk7R0Lq0nbPYvfD2+/FHyQeqlzNDz22+t3JG3fvXoiPHat3UrarreDD6MlbbbTrOTqW4vhsRsn0nO0rsTnHf7su/vVmc2N3TDy2AZ2s+dg6+5dM/ugpC9Jqkt6wt1fnFjPgH3C2MY0jPWZrbt/UdIXJ9QXYGYwtjFpVJABQAEEWwAogGALAAVMfZ7tDiZ1h5Lb/YW4QskX09kIh5bimQDLi2l7NOtAkg4HswmWm5vhsSeCGQZ3tK6Fx55aeDtp+/HF15K2n2hdD2+/ZOmsge92N8Jjn1v4R0nb/6nfGx77Vjud/3m1Hc8wuLKZtr/Rjeuph6vCJKkRVKtJUn94lM38ZATsxZe+d37sc/yrf3jfBHoym7iyBYACCLYAUADBFgAKINgCQAFFE2RuUn8oD5Rb3rAWJMiiRJgUJ8OiUltJqgftrXpmacBgAd1OtNBuRnTsW734vtYtTZy91r0tPPZ7nbTG+VgjTeZJUidYMHi9mybjpPxzNq7kaSRBdsub50RYDle2AFAAwRYACiDYAkABBFsAKIBgCwAFlC3XlWRDEwdqnTg13Q02bIxmEkxCuxfPMDjeSjP8tzXictvlWlrye7mX7rb6Da/+lL+RmY2w2kvLateHp3kMXO+lC3p3+/F7bCdo98zGmbVgg8lavAZ7OhthzI2IMZtuxRkGo+DKFgAKINgCQAEEWwAoYKzPbM3sVUnXJPUkdd19ZRKdAvYbYxuTNokE2b9w93jL2DFYLc2iLLfict2GpYmzXDLtaCtdIza6vRSXuua0g8TXD3rp1u25pFckl/SKRLvzStKhepq1ip4DSWoEz9nbS+l6uJLUXUi37u4342RaUPV8UExlbOPWdHD/DADgABk32LqkPzGzr5nZ6Ul0CJgRjG1M1LgfI/y0u18wsx+S9JSZ/bW7f3n7AYOBelqSGkdvH/PugGJGGtuLij9uAW4Y68rW3S8M/r0k6Q8kPRAcc8bdV9x9pb6cTvIHZtGoY7up9DNsYLs9B1szWzazIze+l/QvJb0wqY4B+4WxjWkY52OEOyX9gZndOM//dvc/3u1Gw0l7zywkXQtmIyzU4x1zF4OMe25B8KgENydakPv2xlp47In6atK24Wmp7CiO1eO+rtXTq6hLnaPxOZrpOZq1+Lk50khLji8tpTMqJOn7zSNJW27WwQFcPHxPYxu4mT0HW3f/jqSfmGBfgJnA2MY0MPULAAog2AJAAQRbACig7O66Nam7tDPx1TsUl8oeWUqTNaeWroTHRkmgpXpcvnqq9fZu3fz/ojVq/0HjcnjsiVr1xFukGZQMdzIZp6ueJsiiBJ0UlwfnyoA3+2lC78KhuLz4zSNpkq2zGg+nfmPna36Ay3dvSV/63vli9zXPa+Iy7AGgAIItABRAsAWAAgi2AFAAwRYACii7u27D1T2xs7S2eTieNfCu4+mazT+8/EZ4bNPSzHhuMe1oNkEruP3WedPy4LsbV8NjjwdvWx1PS46bVr1W9Vo/7tdtSsuTT9TiXX+P1dPy4mjXXymeuXDnoWvhsS+30tkTw7MObujctvNYr74mOwoqOetgEn04aDMXuLIFgAIItgBQAMEWAAog2AJAAWUTZDXJhhIrrVYmCRTsAJtLekUJslaQ3JqEpuIkUNPSrE+02eySxaWyHQ+eh1qaCJOka/24DwBmF1e2AFAAwRYACiDYAkABBFsAKGDXBJmZPSHp5yRdcvcfG7Qdl/R7ku6R9KqkX3T36gvFbtNqxImsRrC+a5QIk+JkWO7YURyppUm6xSltVrhUSxNnnUwF2WLw2DqK1wWOnoeoMi6n059AudeMbvg47bENbFflyvZJSQ8OtT0m6Wl3v1fS04OfgYPmSTG2UciuwdbdvyzpraHmhySdHXx/VtLDE+4XMHWMbZS0189s73T3i4Pv35B0Z+5AMzttZufM7FzvarooCjBj9jS2O0q3UAK2GztB5u4uZWb6b/3+jLuvuPtK/Wi82hQwi0YZ202l+8IB2+012L5pZiclafDvpcl1CdhXjG1MxV7Ldb8g6VFJHx38+/lKt3LJuzvje7sbd+F6L93p9UrvUHjsbfV4LddIx9P7y61n2woy/BuZ65yNXrXZD51ghoMkNS193+t4PMMgst6Pn8f1fnrFda0fP4/RrrvdEbbCnZN1avc2tg+YWVi79laz61+SmX1K0v+V9CNm9rqZfUBbA/F9ZvYtST87+Bk4UBjbKGnXK1t3fyTzq/dOuC9AUYxtlEQFGQAUQLAFgALKrmcbqNfiJNB6N02QXWofjU8SLBE7iXLdq7VgOk/1nJXawXvZuselsktBf9czGae1IMn3Vu9weOwPgvbLvaXw2Lc76dS89W68/m5kAk85Cok2Sxx3s8VJJN0O2iaOo+DKFgAKINgCQAEEWwAogGALAAUQbAGggOKzEay2s941NxshstaLF/tY7S0mbbnZCJ0gw9+ux09DuMh2piR10eKdcKuKZh78IFNWG80miMqQc8e+3Y0XBIqem5zh11G6Sbnu8EvM5sAzqeRMgHmedZDDlS0AFECwBYACCLYAUADBFgAKKJsgc8m71bZW7QbZlmiNW0la76UlpaMkyHLHRiWwubVvO1YxuZRZz3bD08eWK6uN1qPNJbei9tyxuQTkuKw/I9vpYqpuxaTXKLiyBYACCLYAUADBFgAKINgCQAFV9iB7wswumdkL29p+08wumNn5wdf7p9tNYPIY2yipymyEJyX9N0n/a6j94+7+2yPdm0tq74zvG+14hsFmsOvu9UZ87Chlpp1eeuzhejxDYC3YmTZq25K2RzMM1mrVdwLO7YIbPd5cv6LS3Cvd+LzRbI/odZAkD2YY1DrxrIP+cCXz7JTrPqlJjW1gF7te2br7lyW9VaAvQFGMbZQ0zme2HzSz5wf/Fbt9Yj0C9h9jGxO312D7CUnvknSfpIuSfid3oJmdNrNzZnaut7q2x7sDitnT2O5os1T/cEDtKdi6+5vu3nP3vqTflfTATY494+4r7r5SPxwv7QfMir2O7WbwmT2w3Z7Kdc3spLtfHPz485JeuNnxN9PtxvF+s5d2rR0ktyTp+5tpWW2zFpfVHqqn685G6+FK0lKtnbRFSS+p+nq2uXVnI7mk15VenOAKjw2SYWvdzHnb6fOw2snsrttOX7fg6doSVx3PpEmObWC7Xf/yzexTkn5G0jvM7HVJ/0nSz5jZfdrKK78q6dem2EdgKhjbKGnXYOvujwTNj0+hL0BRjG2URAUZABRAsAWAAgi2AFBA8d11h8N7LdilVYp33W3V4xkGuZkHVXX68SyH9X6aiV+ujTefMtyxN2OU+4r6Whxv3UAWfx4AUADBFgAKINgCQAEEWwAooHyCbAaNsh7uuOcdpVx3lB1zR9H1+D12I1jPtp1ZzxbAaLiyBYACCLYAUADBFgAKINgCQAEEWwAooHyqeagKtx/s0ipJG0EWfL0bl6Q2LC3tzZXwRqW5ndr4sxGqzhDILT4+yo65o5Tmtvvp85grT+710/feXub1ATAarmwBoACCLQAUQLAFgAJ2DbZmdreZPWNmL5nZi2b2oUH7cTN7ysy+Nfj39ul3F5gcxjZKqpIg60r6iLt/3cyOSPqamT0l6VclPe3uHzWzxyQ9JunXb34qk1VMuDSD9WxHESXNRhXtuhvtuCtJTau2pm7uuKh9lGNzOwRHybBcuW6uvarszTNrFs+ACY5t4OZ2/ety94vu/vXB99ckvSzplKSHJJ0dHHZW0sPT6iQwDYxtlDTSpYyZ3SPpfknPSrrT3S8OfvWGpDsn2jOgIMY2pq1ysDWzw5I+K+nD7n51++/c3SWF/1c0s9Nmds7MzvVWV8fqLDANkxjbHY23XRLmX6Vga2ZNbQ3GT7r75wbNb5rZycHvT0q6FN3W3c+4+4q7r9QPH55En4GJmdTYbiouQAFu2DVBZmYm6XFJL7v7x7b96guSHpX00cG/n9/97lw+lCxpNOJE1kI93RhxqZFJTgXVYqNsAlk1uXWzY1sjbOQ4rqgPuQq26HkYJXkYVZXNi8mObeDmqsxG+ClJvyLpr8zs/KDtN7Q1ED9jZh+Q9DeSfnE6XQSmhrGNYnYNtu7+FUm5+VrvnWx3gHIY2yhpfv+PCAAzhGALAAUQbAGggLndOjW3ZusosxQO1zeStuVaPJ9y0TpJW7R2bXRc7thp7a47ynOQFUxoyE5yYE1cgCtbACiBYAsABRBsAaAAgi0AFFA2QeamWntnfO92q6+t2u7FiaGo/LRRH38920guOZVLfI0jVxoc9SGXEBxXrlw3XJc485QnL8/MLm8LTA9XtgBQAMEWAAog2AJAAQRbACiAYAsABex7uW5thJ1XW/XqZabXe2n5qyQtN9Jy21EWD8+Jym0jzcwi41F7bubDulpJ21I9Xlj9cncpPe8IMxf6I5TaemY0eWPoNaZ6F7cgrmwBoACCLQAUQLAFgAJ2DbZmdreZPWNmL5nZi2b2oUH7b5rZBTM7P/h6//S7C0wOYxslVUmQdSV9xN2/bmZHJH3NzJ4a/O7j7v7b0+jYKLu6Tmsn3Ug7lwWqqJO5fS5xFh87gfVoxzVCNXSS55udBNm+jG3cmqps+HhR0sXB99fM7GVJp6bdMWDaGNsoaaTPbM3sHkn3S3p20PRBM3vezJ4ws9sn3DegGMY2pq1ysDWzw5I+K+nD7n5V0ickvUvSfdq6OvidzO1Om9k5MzvXW12bQJeByZrE2O4o3i4JuKFSsDWzprYG4yfd/XOS5O5vunvP3fuSflfSA9Ft3f2Mu6+4+0r98PKk+g1MxKTGdlML5TqNA6nKbAST9Likl939Y9vaT2477OclvTD57gHTw9hGSVVS6z8l6Vck/ZWZnR+0/YakR8zsPm0tBf2qpF/b9UwuDSfSe924dHSjm3ZtvZuWqeZEC4pLcQlsLru/2Q92vK3FZbFj73gb9CE38yFcPDy3E29QmrvejUuLoxkguXLdWqf6lILkoc3O4uGTG9vALqrMRviK4sk6X5x8d4ByGNsoiQoyACiAYAsABRBsAaCAouvZmqeJlW47Tuxcb6dJnLXWKAmyOOm1Vg+m6GSehdwasVWt96v3N0qQ5W6/2ltM2nJr1Ea7FG9k1vrtBAmyXAIzSpBlcpKzXK4LFMOVLQAUQLAFgAIItgBQAMEWAAog2AJAAWV31+1L9es7U9GddhzvN9tp19ba45frjrJD71JQmrtQ61S+fTRrYBS524cluJmZC9Gxm734ZY/KdXvd+PVZuB5MKRhhQXHgVsOVLQAUQLAFgAIItgBQAMEWAAooW67bl5qrO9va63E5aHsxLSldbcQZmHZQUlqvxYumRuWr6804uXQ9KGu93F0Kj23V0t1x2/306b1SOxTePirXXevFq/9HSa+or5J0tZMm2XKJxqhE2jfi12f4dZTy5brdDat0HDDPuLIFgAIItgBQAMEWAAqosuHjopl91cz+0sxeNLPfGrS/08yeNbNXzOz3zKx6xQEwAxjbKKlKgmxT0nvcfXWw7fNXzOyPJP07SR9390+b2f+Q9AFJn9jtZMPJkcyys+GegLnNB6PKp1w5U3RsN7x9nEzLiZJhuTVmQ8FdjbJG7Sh9rdcy1XWN4MXIPOf1zaAxk/iqbQ6dY3Y2fJzo2AZuZte/UN9yI/fcHHy5pPdI+v1B+1lJD0+lh8CUMLZRUqXLITOrD7Z6viTpKUnflnTZ3W/Md3pd0qnpdBGYHsY2SqkUbN295+73SbpL0gOSfrTqHZjZaTM7Z2bneutre+wmMB2TGtsdRZ+rAH9vpNkI7n5Z0jOS/rmkY2Z244PKuyRdyNzmjLuvuPtKfWl5rM4C0zLu2G4qLkABbqgyG+EOMzs2+P6QpPdJellbA/MXBoc9Kunz0+okMA2MbZRUZTbCSUlnzayureD8GXf/QzN7SdKnzew/S/oLSY/veiaTekOTaPoLcWq6tZiuG7u8GO9222qkpbI5Rxc20rZm2iZJ71hIa1Jva1yvfF/RbIJmbbz1dCWpk2xXK13uxGXEh+rp85ibfdFrpu0/WDwSHtuvp0Mn987dbw69xrOzu+7kxjawi12Drbs/L+n+oP072vqMCziQGNsoiQoyACiAYAsABRBsAaCAouvZuknD+xJ6K67xXAqSYcutOGG01Ezbj7bipFeUMIrapDgZ9kPNq+GxkSiRlUt6tSxN8q314+lE0eaOS/X4vFe68fq5Vb12+FjY7o20b+04R6fe0s4E2QiVxcDcYNgDQAEEWwAogGALAAUQbAGgAIItABRQdDaCVD0THS8IPrui3XGj2QjTuq+oLdfeyGxvGy1A3owWFJfUDfYu6KUb+UqS+ktD58jsfAzMs4MV0QDggCLYAkABBFsAKIBgCwAFlE2Q2Xilmp3cOqxBe7sXJ6ei5FAuYfS9jbRUNbfjbbRO7Sjr2Y6SYIvOG5XwStJaNy2rvd5rhsdGCbLNdjxEmsESwh5XDMs2hs6b2bEXmGdc2QJAAQRbACiAYAsABVTZ8HHRzL5qZn9pZi+a2W8N2p80s++a2fnB133T7y4wOYxtlFQlQbYp6T3uvmpmTUlfMbM/Gvzu37v770+ve8BUMbZRTJUNH13SjW1mm4OvvdVbupQk/jOZ6U43zbi3u3F30z1wpc1efOxaPU2jLzc3w2Nb9aAsNjOboFVLz9vup32IjsuJbp87x5VOvEh4buZBeH+ZGRyRaFZJZlKHap2h13hGqnUnOraBXVT6zNbM6mZ2XtIlSU+5+7ODX/0XM3vezD5uZvG2AsAMY2yjlErB1t177n6fpLskPWBmPybpP0j6UUn/VNJxSb8e3dbMTpvZOTM711tfm1C3gcmY1NjuKP7fEXDDSLMR3P2ypGckPejuF33LpqT/KemBzG3OuPuKu6/Ul5bH7zEwBeOO7aa4+MXNVZmNcIeZHRt8f0jS+yT9tZmdHLSZpIclvTDNjgKTxthGSVVmI5yUdNbM6toKzp9x9z80sz8zszskmaTzkv7NbieyvtQcymZ1rsVJmY2ltPy0243fG2ojrI/aaKRZnEOteHfdo4vpDr3r0UKukhpBuW13zPVsu5ny5EYtfQxrnbhfG0FSsRncPndsez0+b6t6ni9JkNnspKAmNraB3VSZjfC8pPuD9vdMpUdAIYxtlEQFGQAUQLAFgAIItgBQAMEWAAoouni49aXG2s5UdHM1LtfdXEjLTDutTHdHmI2w2UiPvd6KM+7XWuncyYUR0vDRoub1zEyAqreXpFYjKA3OlDK329VnRHQ30ue89neZ2QhXqj/n3cWh17j6UwDMDa5sAaAAgi0AFECwBYACCLYAUEDRBFl903XbqzuTOwtX4gRO+0j6PtBvxMm0frRka+ZtJFqHNbNsrHqLadtGkGAbxQj5qvw5RniLrF9Pn7PcDseLQe5v4e342COvxyXOERtaW7ie2YUXmGdc2QJAAQRbACiAYAsABRBsAaAAgi0AFFC2XPfqulp//NyOtsXleKscW1pK21rxTrF+aIQtSWrB+0s9854THOuN6u9PHt2+Of77mwf9rXXiXX8taO8djp8vD2Z71NfiWQe1b/7tzbq4w6G7T+74+ZW1EVYeB+YEV7YAUADBFgAKINgCQAEEWwAowNzLbXVqZn8n6W8GP75D0veL3Xk5PK7d/WN3v2NC55oJ28b2vL7+0vw+tiJju2iw3XHHZufcfWVf7nyKeFy3tnl+nub1sZV6XHyMAAAFEGwBoID9DLZn9vG+p4nHdWub5+dpXh9bkce1b5/ZAsCthI8RAKCA4sHWzB40s2+Y2Stm9ljp+58kM3vCzC6Z2Qvb2o6b2VNm9q3Bv7fvZx/3wszuNrNnzOwlM3vRzD40aD/wj22a5mVsM66n89iKBlszq0v675L+taR3S3rEzN5dsg8T9qSkB4faHpP0tLvfK+npwc8HTVfSR9z93ZJ+UtK/HbxO8/DYpmLOxvaTYlxPXOkr2wckveLu33H3tqRPS3qocB8mxt2/LOmtoeaHJJ0dfH9W0sNFOzUB7n7R3b8++P6apJclndIcPLYpmpuxzbiezmMrHWxPSXpt28+vD9rmyZ3ufnHw/RuS7tzPzozLzO6RdL+kZzVnj23C5n1sz9Vrvx/jmgTZFPnWVI8DO93DzA5L+qykD7v71e2/O+iPDXt30F/7/RrXpYPtBUl3b/v5rkHbPHnTzE5K0uDfS/vcnz0xs6a2BuQn3f1zg+a5eGxTMu9jey5e+/0c16WD7XOS7jWzd5pZS9IvSfpC4T5M2xckPTr4/lFJn9/HvuyJmZmkxyW97O4f2/arA//Ypmjex/aBf+33fVy7e9EvSe+X9E1J35b0H0vf/4Qfy6ckXZTU0dZndB+QdEJbGc1vSfpTScf3u597eFw/ra3/Sj0v6fzg6/3z8Nim/LzNxdhmXE/nsVFBBgAFkCADgAIItgBQAMEWAAog2AJAAQRbACiAYAsABRBsAaAAgi0AFPD/ADShsrFG2E0VAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "csv_im = pd.read_csv('/content/binary_images/110.csv', sep = ',', header=None)\n",
        "plt.imshow(csv_im)\n",
        "\n",
        "image_binarizer(110, 0.92, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data Set"
      ],
      "metadata": {
        "id": "a7XPDMoo5MjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "input_img_paths = sorted(\n",
        "    [os.path.join(input_dir, fname)\n",
        "    for fname in os.listdir(input_dir)\n",
        "    if fname.endswith(\".jpg\")])\n",
        "    \n",
        "target_paths = sorted([os.path.join(target_dir, fname)\n",
        "    for fname in os.listdir(target_dir)\n",
        "    if fname.endswith(\".png\") and not fname.startswith(\".\")])"
      ],
      "metadata": {
        "id": "D42RVEX05W0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.axis(\"off\")\n",
        "\n",
        "# Display input image number 9\n",
        "plt.imshow(load_img(input_img_paths[9]))"
      ],
      "metadata": {
        "id": "veFL20Lc5gE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data into NumPy Array"
      ],
      "metadata": {
        "id": "fKi8MnkP5mce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We resize everything to 160x160\n",
        "img_size = (160, 160)\n",
        "# Total number of samples in the data\n",
        "num_imgs = len(input_img_paths)\n",
        "\n",
        "# Shuffle the file paths (they were originally sorted by breed). We \n",
        "# use the same seed (1337) in both statements to ensure that the input \n",
        "# paths and target paths stay in the same order\n",
        "\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_paths)\n",
        "\n",
        "def path_to_input_image(path):\n",
        "    return img_to_array(load_img(path, target_size=img_size))\n",
        "\n",
        "def path_to_target(path):\n",
        "    img = img_to_array(\n",
        "    load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
        "    # Subtract 1 so that our labels become 0, 1, and 2\n",
        "    img = img.astype(\"uint8\") - 1\n",
        "    return img\n",
        "\n",
        "# Load all images in the input_imgs float32 array and their masks in the\n",
        "# targets uint8 array (same order). The inputs have three channels (RBG values)\n",
        "# and the targets have a single channel (which contains integer labels)\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
        "for i in range(num_imgs):\n",
        "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
        "    targets[i] = path_to_target(target_paths[i])\n",
        "  \n",
        "# Reserve 1000 samples for validation\n",
        "num_val_samples = 1000\n",
        "\n",
        "# Split the data into a training and a\n",
        "# validation set\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]"
      ],
      "metadata": {
        "id": "jFqExwEh5tve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "gyGuS26UJmDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We resize everything to 160x160\n",
        "img_size = (160, 160)\n",
        "# Total number of samples in the data\n",
        "num_imgs = len(input_img_paths)\n",
        "\n",
        "# Shuffle the file paths (they were originally sorted by breed). We \n",
        "# use the same seed (1337) in both statements to ensure that the input \n",
        "# paths and target paths stay in the same order\n",
        "\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_paths)\n",
        "\n",
        "def path_to_input_image(path):\n",
        "    return img_to_array(load_img(path, target_size=img_size))\n",
        "\n",
        "def path_to_target(path):\n",
        "    img = img_to_array(\n",
        "    load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
        "    # Subtract 1 so that our labels become 0, 1, and 2\n",
        "    img = img.astype(\"uint8\") - 1\n",
        "    return img\n",
        "\n",
        "# Load all images in the input_imgs float32 array and their masks in the\n",
        "# targets uint8 array (same order). The inputs have three channels (RBG values)\n",
        "# and the targets have a single channel (which contains integer labels)\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
        "for i in range(num_imgs):\n",
        "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
        "    targets[i] = path_to_target(target_paths[i])\n",
        "  \n",
        "# Reserve 1000 samples for validation\n",
        "num_val_samples = 1000\n",
        "\n",
        "# Split the data into a training and a\n",
        "# validation set\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]"
      ],
      "metadata": {
        "id": "Caa6SjwI5w7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "83bfVqww53nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=\"unet_segmentation.keras\", save_best_only=True, monitor=\"val_loss\"),\n",
        "    tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "] \n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    batch_size=64,\n",
        "    validation_data=(val_input_imgs, val_targets))"
      ],
      "metadata": {
        "id": "V8EJj7ZU55fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "Wxmus0-U59Nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Validation Loss"
      ],
      "metadata": {
        "id": "7m7CXB4O6AYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ksO3lrHS6Ffp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Prediction"
      ],
      "metadata": {
        "id": "3KOjunR16Ly6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = keras.models.load_model(\"unet_segmentation.keras\")\n",
        "i = 4\n",
        "test_image = val_input_imgs[i]\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(array_to_img(test_image))\n",
        "mask = model.predict(np.expand_dims(test_image, 0))[0]\n",
        "\n",
        "# Utility to display a model’s prediction\n",
        "def display_mask(pred):\n",
        "    mask = np.argmax(pred, axis=-1)\n",
        "    mask *= 127\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(mask)\n",
        "    \n",
        "display_mask(mask)"
      ],
      "metadata": {
        "id": "ecBZfCxS6LXt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}